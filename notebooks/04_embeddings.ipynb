{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646a1c41",
   "metadata": {},
   "source": [
    "### Génération d’embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d74b3dc",
   "metadata": {},
   "source": [
    "##### 1. Le choix de modèles génération d’embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ccbeb",
   "metadata": {},
   "source": [
    "Parmi les meilleurs modèles de génération d’embeddings, on trouve :\n",
    "\n",
    "| Modèle              | Qualité         | Multilingue       | Vitesse |\n",
    "| ------------------- | --------------- | ----------------- | ------- |\n",
    "| BGE-large-m3        | Excellent       | Oui               | Lent |\n",
    "| E5-large-v2         | Excellent       | EN only           | Moyen |\n",
    "| Multilingual-E5     | Bien            | Oui               | Moyen |\n",
    "| GTE-large           | Bien            | EN only           | Rapide |\n",
    "| MiniLM-L12-v2       | qualité faible  | Oui               | Très rapide |\n",
    "\n",
    "\n",
    "On va utiliser `E5-large-v2` pour trouver un équilibre entre la performance et la vitesse d’entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da323e",
   "metadata": {},
   "source": [
    "##### 2. Prétraitement des textes pour le modéle `E5-large-v2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f13757",
   "metadata": {},
   "source": [
    "Le modèle `E5-large-v2` a été entraîné sur du texte naturel (phrases réelles, majuscules, ponctuation, etc.), donc il faut garder le texte aussi proche que possible de sa forme originale,\n",
    "tout en nettoyant les erreurs mineures ou les incohérences.\n",
    "\n",
    "il est recommander d'éviter de:\n",
    "- Supprimer les stopwords: Le modèle comprend leur rôle sémantique.\n",
    "- Lemmatisation ou stemming: Cela modifie la structure linguistique et le sens.\n",
    "- Supprimer la ponctuation: La ponctuation aide à comprendre le contexte.\n",
    "- Tout mettre en minuscules (Sauf si le texte contient des majuscules aléatoires ou tout en majuscules.): Peut faire perdre des distinctions importantes (Apple ≠ apple, US ≠ us).\n",
    "- Supprimer les chiffres: Les nombres ont souvent une signification utile (dates, montants…).\n",
    "\n",
    "Il est Recommander (et parfois obligatoire) de:\n",
    "- Supprimer les espaces inutiles: Nettoyer les débuts/fin de lignes et les espaces multiples.\n",
    "- Gérer les valeurs manquantes: Remplacer les `NaN` ou textes vides par une chaîne vide.\n",
    "- Ajouter le préfixe (Obligatoire): **\"passage: \"** pour les documents, **\"query: \"** pour les requêtes.\n",
    "- Tronquer les textes très longs: Si un texte dépasse la limite (512 tokens environ), on peut le couper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "108e5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv('../data/raw/train.csv')\n",
    "data_test = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "\n",
    "data_train[\"text\"] = data_train[\"text\"].fillna(\"\").str.strip()\n",
    "data_test[\"text\"] = data_test[\"text\"].fillna(\"\").str.strip()\n",
    "\n",
    "\n",
    "data_train[\"text\"] = data_train[\"text\"].str.replace(r\"\\s+\", \" \", regex=True)\n",
    "data_test[\"text\"] = data_test[\"text\"].str.replace(r\"\\s+\", \" \", regex=True)\n",
    "\n",
    "\n",
    "data_train[\"text_prefixed\"] = \"passage: \" + data_train[\"text\"]\n",
    "data_test[\"text_prefixed\"] = \"passage: \" + data_test[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e8e6b",
   "metadata": {},
   "source": [
    "- Sauvegarder les modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb53945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv('../data/processed/preprocessed_train_text.csv', index=False)\n",
    "data_test.to_csv('../data/processed/preprocessed_test_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1861d0b1",
   "metadata": {},
   "source": [
    "##### 3. Charger le modèle `e5-large-v2` avec **Sentence Transformers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377899c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"intfloat/e5-large-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73682ab6",
   "metadata": {},
   "source": [
    "##### 4. Générer les embeddings pour toutes les données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec6565b",
   "metadata": {},
   "source": [
    "- Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ae2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"embedding\"] = data_train[\"text_prefixed\"].apply(\n",
    "    lambda x: model.encode(x, normalize_embeddings=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af267641",
   "metadata": {},
   "source": [
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc4f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"embedding\"] = data_test[\"text_prefixed\"].apply(\n",
    "    lambda x: model.encode(x, normalize_embeddings=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf9e90",
   "metadata": {},
   "source": [
    "Malheureusement, la génération des embeddings prend beaucoup de temps (plus de 400 minutes pour les données d'entraînement sans se terminer). Nous allons donc utiliser un autre modèle qui est plus rapide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f84f64",
   "metadata": {},
   "source": [
    "##### 5. Générer les embeddings avec le modèle `paraphrase-multilingual-MiniLM-L12-v2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03f7c04",
   "metadata": {},
   "source": [
    "Prétraiter le texte:\n",
    "\n",
    "- Supprimer les espaces inutiles: Nettoyer les débuts/fin de lignes et les espaces multiples.\n",
    "- Gérer les valeurs manquantes: Remplacer les `NaN` ou textes vides par une chaîne vide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2801fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cfb9e1",
   "metadata": {},
   "source": [
    "- Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6da54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3750/3750 [1:19:32<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "data_train[\"text\"] = data_train[\"text\"].fillna(\"\").str.strip()\n",
    "data_train[\"text\"] = data_train[\"text\"].str.replace(r\"\\s+\", \" \", regex=True)\n",
    "\n",
    "texts = data_train[\"text\"].tolist()\n",
    "\n",
    "train_embeddings = model.encode(\n",
    "    texts,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87309b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "\n",
    "os.makedirs('../data/embeddings', exist_ok=True)\n",
    "\n",
    "np.save(\"../data/embeddings/train_embeddings_minilm.npy\", train_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e224106",
   "metadata": {},
   "source": [
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc5ebf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 238/238 [02:04<00:00,  1.92it/s]\n"
     ]
    }
   ],
   "source": [
    "data_test[\"text\"] = data_test[\"text\"].fillna(\"\").str.strip()\n",
    "data_test[\"text\"] = data_test[\"text\"].str.replace(r\"\\s+\", \" \", regex=True)\n",
    "\n",
    "texts = data_test[\"text\"].tolist()\n",
    "\n",
    "test_embeddings = model.encode(\n",
    "    texts,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8efdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "\n",
    "os.makedirs('../data/embeddings', exist_ok=True)\n",
    "\n",
    "np.save(\"../data/embeddings/test_embeddings_minilm.npy\", test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002ddbb",
   "metadata": {},
   "source": [
    "- Sauvegardez le modéle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "908a2e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/minilm_embedding_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib as jb\n",
    "\n",
    "jb.dump(model, '../models/minilm_embedding_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83cb91",
   "metadata": {},
   "source": [
    "##### 6. Vérification des embeddings générés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f69009f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 384) \n",
      "\n",
      "[[ 0.07367805 -0.02631132  0.03900679 ... -0.07857122  0.05455048\n",
      "   0.0741483 ]\n",
      " [-0.00685681 -0.06906829 -0.04574033 ... -0.06036082  0.04355336\n",
      "   0.04123305]\n",
      " [-0.01750736 -0.03781662  0.024446   ... -0.11092535 -0.02253907\n",
      "   0.04098494]\n",
      " ...\n",
      " [-0.02288848  0.01629857 -0.03647588 ...  0.03625313  0.02009865\n",
      "   0.04081287]\n",
      " [-0.03029879 -0.02274068 -0.00463905 ...  0.01157964 -0.01234239\n",
      "   0.02648926]\n",
      " [-0.03888905 -0.05788028 -0.02970092 ...  0.0345937   0.02085045\n",
      "  -0.06742197]]\n"
     ]
    }
   ],
   "source": [
    "print(train_embeddings.shape, '\\n')\n",
    "print(train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62a47426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7600, 384) \n",
      "\n",
      "[[-0.02000974  0.14546126 -0.02131354 ... -0.0077236   0.01787492\n",
      "   0.03831412]\n",
      " [-0.01230167  0.06320839 -0.03357151 ... -0.03042849 -0.1500939\n",
      "   0.0277649 ]\n",
      " [-0.10158303  0.0071192  -0.04032289 ...  0.030038    0.07575675\n",
      "   0.06632863]\n",
      " ...\n",
      " [ 0.04286214  0.02248745  0.00892183 ...  0.02532074  0.09171098\n",
      "  -0.02843746]\n",
      " [-0.01266828 -0.00183072  0.03382643 ... -0.09408851  0.04791066\n",
      "   0.06749152]\n",
      " [ 0.02815873 -0.03605843  0.03330523 ... -0.10941093  0.00155406\n",
      "  -0.04573366]]\n"
     ]
    }
   ],
   "source": [
    "print(test_embeddings.shape, '\\n')\n",
    "print(test_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
